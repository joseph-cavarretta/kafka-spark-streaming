networks:
  kafka-spark:
    name: kafka-spark
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.18.0.0/24
          gateway: 172.18.0.1

services:
  zookeeper:  
    image: bitnami/zookeeper:latest
    container_name: zookeeper
    hostname: zookeeper
    ports:
      - 2181:2181
    environment:
      ALLOW_ANONYMOUS_LOGIN: yes
    healthcheck:
      test: ["CMD", "echo", "ruok", "|", "nc", "172.18.0.2", "2181", "|", "grep", "imok"]
      timeout: 10s
      retries: 10
    networks:
      kafka-spark:
        ipv4_address: 172.18.0.2

  kafka:
    image: bitnami/kafka:latest
    container_name: kafka
    hostname: kafka
    ports:
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_CFG_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper:2181
      ALLOW_PLAINTEXT_LISTENER: yes
      KAFKA_CREATE_TOPICS: events-topic:1:1
    healthcheck:
      test: ["CMD", "/opt/bitnami/kafka/bin/kafka-topics.sh", "--list", "--bootstrap-server", "kafka:9092"]
      timeout: 10s
      retries: 10
    depends_on:
      zookeeper:
        condition: service_healthy
    # volumes:
    #   - kafka_data:/data
    networks:
      kafka-spark:
        ipv4_address: 172.18.0.3

  schema-registry:
    image: confluentinc/cp-schema-registry:latest
    container_name: schema-registry
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:9092
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
    ports:
      - 8081:8081
    healthcheck:
      test: ["CMD", "curl", "-f", "http://schema-registry:8081/"]
      timeout: 10s
      retries: 10
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      kafka-spark:
        ipv4_address: 172.18.0.4

  spark:
    image: bitnami/spark:3
    container_name: spark-master
    hostname: spark-master
    build:
      context: ./src
      dockerfile: consumer/Dockerfile
    ports:
      - 7077:7077  # Spark master port
      - 8080:8080  # Spark UI port
    user: root
    environment:
      SPARK_MODE: master
      SPARK_RPC_AUTHENTICATION_ENABLED: no
      SPARK_RPC_ENCRYPTION_ENABLED: no
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: no
      SPARK_SSL_ENABLED: no
    depends_on:
      schema-registry:
        condition: service_healthy
    # volumes:
    #   - spark_data:/data
    #   - /opt/spark/conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    #   - /opt/spark/jars:/opt/bitnami/spark/ivy:z
    networks:
      kafka-spark:
        ipv4_address: 172.18.0.5

  # cassandra:
  #   image: bitnami/cassandra:latest
  #   container_name: cassandra
  #   hostname: cassandra
  #   ports:
  #     - 9042:9042
  #   environment:
  #     - CASSANDRA_CLUSTER_NAME=test-cluster
  #   # volumes:
  #   #   - cassandra:/data
  #   healthcheck:
  #     test: ["CMD", "nodetool", "status"]
  #     timeout: 10s
  #     retries: 10
  #   depends_on:
  #     schema-registry:
  #       condition: service_healthy
  #   networks:
  #     kafka-spark:
  #       ipv4_address: 172.18.0.6

  python-producer:
    image: python:3.12.1-slim
    container_name: python-producer
    hostname: python-producer
    build:
      context: ./src
      dockerfile: producer/Dockerfile
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092  # kafka connection
      - KAFKA_TOPIC=test-topic
    depends_on:
      schema-registry:
        condition: service_healthy
    networks:
      kafka-spark:
        ipv4_address: 172.18.0.7
